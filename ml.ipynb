{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0eaf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Q1.\n",
    "# (a) Create a 1D NumPy array with values 1 to 20\n",
    "# (b) Extract all prime numbers\n",
    "# (c) Compute mean and variance of primes\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "arr = np.arange(1, 21)\n",
    "\n",
    "def is_prime(n):\n",
    "    if n < 2:\n",
    "        return False\n",
    "    for i in range(2, int(np.sqrt(n)) + 1):\n",
    "        if n % i == 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "primes = np.array([x for x in arr if is_prime(x)])\n",
    "print(\"Q1 Primes:\", primes)\n",
    "print(\"Mean:\", np.mean(primes))\n",
    "print(\"Variance:\", np.var(primes))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Q2.\n",
    "# (a) Create a 4×4 array (1–16)\n",
    "# (b) Extract 2×2 bottom-left sub-matrix\n",
    "# (c) Compute determinant\n",
    "# ============================================================\n",
    "\n",
    "A = np.arange(1, 17).reshape(4, 4)\n",
    "sub = A[2:4, 0:2]\n",
    "print(\"\\nQ2 Sub-matrix:\\n\", sub)\n",
    "print(\"Determinant:\", np.linalg.det(sub))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Q3.\n",
    "# Student DataFrame – total, average, topper\n",
    "# ============================================================\n",
    "\n",
    "students = pd.DataFrame({\n",
    "    \"Name\": [\"A\", \"B\", \"C\", \"D\", \"E\"],\n",
    "    \"Math\": [80, 75, 90, 60, 85],\n",
    "    \"Science\": [70, 88, 95, 65, 80],\n",
    "    \"English\": [75, 70, 85, 60, 90]\n",
    "})\n",
    "\n",
    "students[\"Total\"] = students.iloc[:, 1:4].sum(axis=1)\n",
    "students[\"Average\"] = students[\"Total\"] / 3\n",
    "topper = students.loc[students[\"Average\"].idxmax()]\n",
    "\n",
    "print(\"\\nQ3 Student Table:\\n\", students)\n",
    "print(\"Topper:\", topper[\"Name\"], \"Avg:\", topper[\"Average\"])\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Q4.\n",
    "# Coin toss simulation (1000 tosses)\n",
    "# ============================================================\n",
    "\n",
    "tosses = np.random.randint(0, 2, 1000)\n",
    "heads = np.sum(tosses == 1)\n",
    "tails = np.sum(tosses == 0)\n",
    "\n",
    "print(\"\\nQ4 Heads:\", heads, \"Tails:\", tails)\n",
    "print(\"Probability of Heads:\", heads / 1000)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Q5.\n",
    "# Employee bonus & salary above average\n",
    "# ============================================================\n",
    "\n",
    "emp = pd.DataFrame({\n",
    "    \"ID\": [1, 2, 3, 4],\n",
    "    \"Name\": [\"A\", \"B\", \"C\", \"D\"],\n",
    "    \"Salary\": [50000, 60000, 55000, 70000]\n",
    "})\n",
    "\n",
    "emp[\"Bonus\"] = emp[\"Salary\"] * 0.10\n",
    "print(\"\\nQ5 Employees above avg salary:\\n\",\n",
    "      emp[emp[\"Salary\"] > emp[\"Salary\"].mean()])\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Q6.\n",
    "# 3×3 matrix transpose, inverse & verification\n",
    "# ============================================================\n",
    "\n",
    "M = np.arange(1, 10).reshape(3, 3)\n",
    "M_inv = np.linalg.inv(M)\n",
    "identity = np.dot(M, M_inv)\n",
    "\n",
    "print(\"\\nQ6 Identity Check:\\n\", identity)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Q7.\n",
    "# Daily temperature analysis\n",
    "# ============================================================\n",
    "\n",
    "temps = np.random.randint(20, 41, 30)\n",
    "print(\"\\nQ7 Hottest:\", temps.max())\n",
    "print(\"Coldest:\", temps.min())\n",
    "print(\"Mean:\", np.mean(temps))\n",
    "print(\"Median:\", np.median(temps))\n",
    "print(\"Std Dev:\", np.std(temps))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Q8.\n",
    "# Pandas Series – Pass/Fail\n",
    "# ============================================================\n",
    "\n",
    "marks = pd.Series([78, 45, 30, 90, 55, 20, 60, 35])\n",
    "marks = marks.where(marks >= 40, \"Fail\")\n",
    "\n",
    "print(\"\\nQ8 Series:\\n\", marks)\n",
    "print(\"Passed Count:\", (marks != \"Fail\").sum())\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Q9.\n",
    "# Dice simulation (500 rolls)\n",
    "# ============================================================\n",
    "\n",
    "dice = np.random.randint(1, 7, 500)\n",
    "counts = pd.Series(dice).value_counts().sort_index()\n",
    "relative = counts / 500\n",
    "\n",
    "print(\"\\nQ9 Dice Counts:\\n\", counts)\n",
    "print(\"Relative Frequency:\\n\", relative)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Q10.\n",
    "# Product sales & max revenue\n",
    "# ============================================================\n",
    "\n",
    "products = pd.DataFrame({\n",
    "    \"Name\": [\"P1\", \"P2\", \"P3\", \"P4\", \"P5\", \"P6\"],\n",
    "    \"Quantity\": [10, 5, 8, 12, 7, 6],\n",
    "    \"Price\": [100, 200, 150, 80, 300, 250]\n",
    "})\n",
    "\n",
    "products[\"Total\"] = products[\"Quantity\"] * products[\"Price\"]\n",
    "print(\"\\nQ10 Max Revenue Product:\\n\",\n",
    "      products.loc[products[\"Total\"].idxmax()])\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Q11.\n",
    "# Missing values handling\n",
    "# ============================================================\n",
    "\n",
    "df_nan = pd.DataFrame({\n",
    "    \"A\": [1, np.nan, 3],\n",
    "    \"B\": [4, 5, np.nan],\n",
    "    \"C\": [np.nan, 8, 9]\n",
    "})\n",
    "\n",
    "print(\"\\nQ11 Filled:\\n\", df_nan.fillna(df_nan.mean()))\n",
    "print(\"Dropped:\\n\", df_nan.dropna(thresh=2))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Q12.\n",
    "# Reshape & even number average\n",
    "# ============================================================\n",
    "\n",
    "arr = np.arange(1, 31)\n",
    "mat = arr.reshape(5, 6)\n",
    "evens = mat[mat % 2 == 0]\n",
    "\n",
    "print(\"\\nQ12 Even Avg:\", evens.mean())\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Q13.\n",
    "# Student filtering\n",
    "# ============================================================\n",
    "\n",
    "stud = pd.DataFrame({\n",
    "    \"Name\": [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"],\n",
    "    \"Age\": [18, 21, 19, 22, 17, 20],\n",
    "    \"Marks\": [65, 75, 55, 80, 90, 60]\n",
    "})\n",
    "\n",
    "print(\"\\nQ13 Above Avg:\\n\",\n",
    "      stud[stud[\"Marks\"] > stud[\"Marks\"].mean()])\n",
    "print(\"Young & High:\\n\",\n",
    "      stud[(stud[\"Age\"] < 20) & (stud[\"Marks\"] > 60)])\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Q14.\n",
    "# Employee efficiency\n",
    "# ============================================================\n",
    "\n",
    "emp2 = pd.DataFrame({\n",
    "    \"Name\": [\"A\", \"B\", \"C\", \"D\", \"E\"],\n",
    "    \"Tasks_Completed\": [40, 35, 50, 45, 30],\n",
    "    \"Hours_Worked\": [8, 7, 10, 9, 6]\n",
    "})\n",
    "\n",
    "emp2[\"Efficiency\"] = emp2[\"Tasks_Completed\"] / emp2[\"Hours_Worked\"]\n",
    "print(\"\\nQ14 Best Employee:\\n\",\n",
    "      emp2.loc[emp2[\"Efficiency\"].idxmax()])\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# CASE STUDY 1 – Student Performance Analytics\n",
    "# ============================================================\n",
    "\n",
    "data = pd.DataFrame(np.random.randint(40, 100, (100, 3)),\n",
    "                    columns=[\"Math\", \"Science\", \"English\"])\n",
    "\n",
    "data[\"Average\"] = data.mean(axis=1)\n",
    "print(\"\\nCase Study 1 – Top 5:\\n\", data.nlargest(5, \"Average\"))\n",
    "print(\"Subject Stats:\\n\", data.iloc[:, :3].agg([\"mean\", \"std\"]))\n",
    "\n",
    "data.iloc[:, :3].boxplot()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# CASE STUDY 2 – Sales Data Exploration\n",
    "# ============================================================\n",
    "\n",
    "sales = pd.DataFrame({\n",
    "    \"Product\": [\"A\", \"B\", \"C\", \"A\", \"B\"],\n",
    "    \"Quantity\": [10, 5, 8, 7, 6],\n",
    "    \"Price\": [100, 200, 150, 100, 200],\n",
    "    \"Region\": [\"East\", \"West\", \"East\", \"North\", \"West\"]\n",
    "})\n",
    "\n",
    "sales[\"Total\"] = sales[\"Quantity\"] * sales[\"Price\"]\n",
    "print(\"\\nCase Study 2 Revenue:\", sales[\"Total\"].sum())\n",
    "print(\"Region-wise:\\n\", sales.groupby(\"Region\")[\"Total\"].sum())\n",
    "\n",
    "sales.groupby(\"Product\")[\"Total\"].sum().plot(kind=\"hist\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# CASE STUDY 3 – Auto MPG (Conceptual)\n",
    "# ============================================================\n",
    "\n",
    "# Correlation: mpg vs weight → strong negative correlation\n",
    "# Scatter plot: weight ↑ → mpg ↓\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4b3843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Q1. Predicting Car MPG using Linear Regression\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# (a) Load dataset and remove missing values\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "auto = pd.read_csv(\"auto_mpg.csv\")\n",
    "auto.dropna(inplace=True)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# (b) Identify predictors and target\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "X = auto.drop(\"mpg\", axis=1)\n",
    "y = auto[\"mpg\"]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# (c) Train-test split (80/20)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# (d) Train Linear Regression model & predict\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# (e) Model evaluation\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nQ1 MSE:\", mse)\n",
    "print(\"Q1 R2 Score:\", r2)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# (f) Discussion:\n",
    "# If R² = 0.85 → 85% of variance in mpg explained by model\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Q2. Bootstrap Sampling for Uncertainty Estimation\n",
    "# ============================================================\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# (a) Load dataset & extract feature columns\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "btissue = pd.read_csv(\"btissue.csv\")\n",
    "X_bt = btissue.iloc[:, :-1]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# (b) Bootstrap sample of 100 observations\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "bootstrap_sample = resample(X_bt, n_samples=100, replace=True, random_state=42)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# (c) Show first 10 rows & check duplicates\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "print(\"\\nQ2 Bootstrap Sample (first 10 rows):\\n\", bootstrap_sample.head(10))\n",
    "print(\"Repeated rows exist:\", bootstrap_sample.duplicated().any())\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Q3. 5-Fold Cross-Validation Index Analysis\n",
    "# ============================================================\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "print(\"\\nQ3 K-Fold Splits:\")\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X_bt)):\n",
    "    print(f\"Fold {fold+1}\")\n",
    "    print(\"Train size:\", len(train_idx))\n",
    "    print(\"Test size:\", len(test_idx))\n",
    "    print(\"Train indices:\", train_idx[:10], \"...\")\n",
    "    print(\"Test indices:\", test_idx[:10], \"...\\n\")\n",
    "\n",
    "# Each fold uses a unique test set; together they cover full dataset\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Q4. Model Evaluation: Holdout vs Cross-Validation\n",
    "# ============================================================\n",
    "\n",
    "X = btissue.iloc[:, :-1]\n",
    "y = btissue.iloc[:, -1]\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# (i) Holdout Validation (80/20)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_tr, y_tr)\n",
    "holdout_acc = model.score(X_te, y_te)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# (ii) 5-Fold Cross-Validation\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "cv_scores = cross_val_score(model, X, y, cv=5)\n",
    "cv_acc = cv_scores.mean()\n",
    "\n",
    "print(\"\\nQ4 Holdout Accuracy:\", holdout_acc)\n",
    "print(\"Q4 CV Accuracy:\", cv_acc)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Q5. Feature Creation from Structured Data\n",
    "# ============================================================\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    \"Age\": [22, 35, 45, 28, 50],\n",
    "    \"Income\": [30000, 60000, 80000, 45000, 90000],\n",
    "    \"Spending\": [2000, 4000, 3000, 2500, 5000]\n",
    "})\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# (a) Feature Engineering\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "data[\"Age_Group\"] = pd.cut(data[\"Age\"], bins=[18, 30, 45, 60],\n",
    "                           labels=[\"Young\", \"Middle\", \"Senior\"])\n",
    "\n",
    "data[\"Income_Spending_Ratio\"] = data[\"Income\"] / data[\"Spending\"]\n",
    "data[\"Normalized_Spending\"] = (\n",
    "    data[\"Spending\"] - data[\"Spending\"].mean()\n",
    ") / data[\"Spending\"].std()\n",
    "\n",
    "print(\"\\nQ5 Feature Engineered Data:\\n\", data)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# (b) Plot correlation\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "data.corr(numeric_only=True).plot(kind=\"bar\")\n",
    "plt.title(\"Feature Correlation\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Q6. Decision Tree on Iris Dataset (Feature Subset Selection)\n",
    "# ============================================================\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# (a) Load Iris dataset\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "iris = load_iris()\n",
    "df_iris = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df_iris[\"target\"] = iris.target\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# (b) Display first rows\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "print(\"\\nQ6 Iris Data:\\n\", df_iris.head())\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# (c) Train with all features\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "X = df_iris.iloc[:, :-1]\n",
    "y = df_iris[\"target\"]\n",
    "\n",
    "dt_all = DecisionTreeClassifier(random_state=42)\n",
    "dt_all.fit(X, y)\n",
    "acc_all = dt_all.score(X, y)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# (d) Select subset using iloc\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "X_subset = df_iris.iloc[:, :2]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# (e) Train with selected features\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "dt_sub = DecisionTreeClassifier(random_state=42)\n",
    "dt_sub.fit(X_subset, y)\n",
    "acc_sub = dt_sub.score(X_subset, y)\n",
    "\n",
    "print(\"\\nAccuracy (All features):\", acc_all)\n",
    "print(\"Accuracy (Subset features):\", acc_sub)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# (f) Discussion:\n",
    "# All features generally give better accuracy\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Q7. PCA on Iris Dataset\n",
    "# ============================================================\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# (a & b) PCA transformation\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(iris.data)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# (c) Create PCA DataFrame\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "pca_df = pd.DataFrame(X_pca, columns=[\"PC1\", \"PC2\"])\n",
    "pca_df[\"target\"] = iris.target\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# (d) Scatter plot\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "for label in np.unique(iris.target):\n",
    "    plt.scatter(\n",
    "        pca_df[pca_df[\"target\"] == label][\"PC1\"],\n",
    "        pca_df[pca_df[\"target\"] == label][\"PC2\"],\n",
    "        label=iris.target_names[label]\n",
    "    )\n",
    "\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.legend()\n",
    "plt.title(\"PCA on Iris Dataset\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nExplained Variance Ratio:\", pca.explained_variance_ratio_)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Q8. Encoding Categorical Variables\n",
    "# ============================================================\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# (a) Create dataset\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "emp = pd.DataFrame({\n",
    "    \"Department\": [\"HR\", \"IT\", \"Finance\", \"IT\", \"HR\"],\n",
    "    \"Job_Role\": [\"Manager\", \"Analyst\", \"Clerk\", \"Manager\", \"Analyst\"],\n",
    "    \"Marital_Status\": [\"Single\", \"Married\", \"Divorced\", \"Single\", \"Married\"]\n",
    "})\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# (b) Display original data\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "print(\"\\nQ8 Original Data:\\n\", emp)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# (c) Encoding\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "le = LabelEncoder()\n",
    "emp[\"Marital_Status\"] = le.fit_transform(emp[\"Marital_Status\"])\n",
    "\n",
    "emp_encoded = pd.get_dummies(emp, columns=[\"Department\", \"Job_Role\"])\n",
    "\n",
    "print(\"\\nEncoded Dataset:\\n\", emp_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6124222c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Q1. Generate Bernoulli and Binomial distributions using NumPy\n",
    "#     and calculate their mean and variance\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -------- Bernoulli Distribution --------\n",
    "p = 0.6                     # probability of success\n",
    "bernoulli = np.random.binomial(1, p, size=1000)\n",
    "\n",
    "print(\"Q1 Bernoulli Distribution\")\n",
    "print(\"Mean:\", np.mean(bernoulli))\n",
    "print(\"Variance:\", np.var(bernoulli))\n",
    "\n",
    "# -------- Binomial Distribution --------\n",
    "n = 10                      # number of trials\n",
    "binomial = np.random.binomial(n, p, size=1000)\n",
    "\n",
    "print(\"\\nQ1 Binomial Distribution\")\n",
    "print(\"Mean:\", np.mean(binomial))\n",
    "print(\"Variance:\", np.var(binomial))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Q2. Generate random samples from a Normal distribution\n",
    "#     and plot its Probability Density Function (PDF)\n",
    "# ============================================================\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "mu = 0\n",
    "sigma = 1\n",
    "\n",
    "samples = np.random.normal(mu, sigma, 1000)\n",
    "\n",
    "# Plot histogram\n",
    "plt.hist(samples, bins=30, density=True, alpha=0.6)\n",
    "\n",
    "# Plot PDF\n",
    "x = np.linspace(-4, 4, 100)\n",
    "plt.plot(x, norm.pdf(x, mu, sigma))\n",
    "\n",
    "plt.title(\"Normal Distribution PDF\")\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Q3. Compute covariance and correlation coefficient\n",
    "#     between two random variables\n",
    "# ============================================================\n",
    "\n",
    "X = np.random.randn(100)\n",
    "Y = 2 * X + np.random.randn(100)\n",
    "\n",
    "# Covariance\n",
    "cov_matrix = np.cov(X, Y)\n",
    "cov_xy = cov_matrix[0, 1]\n",
    "\n",
    "# Correlation\n",
    "corr_xy = np.corrcoef(X, Y)[0, 1]\n",
    "\n",
    "print(\"\\nQ3 Covariance:\", cov_xy)\n",
    "print(\"Q3 Correlation Coefficient:\", corr_xy)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Q4. Verify Central Limit Theorem (CLT)\n",
    "#     by plotting distribution of sample means\n",
    "# ============================================================\n",
    "\n",
    "population = np.random.exponential(scale=2, size=10000)\n",
    "\n",
    "sample_means = []\n",
    "sample_size = 30\n",
    "\n",
    "for _ in range(1000):\n",
    "    sample = np.random.choice(population, sample_size)\n",
    "    sample_means.append(np.mean(sample))\n",
    "\n",
    "plt.hist(sample_means, bins=30, density=True)\n",
    "plt.title(\"Verification of CLT (Distribution of Sample Means)\")\n",
    "plt.xlabel(\"Sample Mean\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Q5. Implement kNN Classifier\n",
    "#     Dataset: Iris.csv / apndcts.csv / btissue.csv\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Load dataset (change filename as needed)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "df = pd.read_csv(\"Iris.csv\")      # or apndcts.csv / btissue.csv\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Separate predictors and target\n",
    "# (Assuming last column is target)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Feature scaling (important for kNN)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Train-test split\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Train kNN classifier\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "k = 5\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Prediction\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Accuracy\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"\\nQ5 kNN Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2788ee9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
